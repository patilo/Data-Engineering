{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fee937-a0b8-4a7c-9c7a-30a3d0df2b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aqui les dejo una guia de como realizar practicas \n",
    "#en la ingenieria de datos\n",
    "#las herramientas que utilizaremos son: s3 - rds - python - sql\n",
    "#crearemos datos ficticios y luego los cargaremos en aws\n",
    "\n",
    "## generamos dataset ficticio con Python\n",
    "import pandas as pd\n",
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "#configuramos generador de datos ficticios\n",
    "faker = Faker()\n",
    "categorias = ['Electrónica', 'Ropa', 'Hogar', 'Alimentos']\n",
    "sucursales = ['Santiago', 'Valparaíso', 'Concepción', 'Antofagasta']\n",
    "metodos_pago = ['Débito', 'Crédito', 'Transferencia']\n",
    "clientes = ['Cliente', 'No Cliente']\n",
    "\n",
    "#creamos datos simulados\n",
    "data = []\n",
    "for _ in range(1000):  # Generar 1000 registros\n",
    "    data.append({\n",
    "        'producto': faker.word(),\n",
    "        'precio': round(random.uniform(10, 1000), 2),\n",
    "        'fecha': faker.date_between(start_date='-1y', end_date='today'),\n",
    "        'sucursal': random.choice(sucursales),\n",
    "        'cantidad': random.randint(1, 10),\n",
    "        'categoria': random.choice(categorias),\n",
    "        'metodo_pago': random.choice(metodos_pago),\n",
    "        'tipo_cliente': random.choice(clientes)\n",
    "    })\n",
    "\n",
    "#guardamos datos en un CSV\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('ventas_simuladas.csv', index=False)\n",
    "print(\"Archivo 'ventas_simuladas.csv' generado.\")\n",
    "#----------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##subiremos datos a AWS S3\n",
    "import boto3\n",
    "\n",
    "#configuramos S3\n",
    "bucket_name = 'mi-bucket-ejemplo'\n",
    "file_name = 'ventas_simuladas.csv'\n",
    "\n",
    "#subimos archivo\n",
    "s3 = boto3.client('s3')\n",
    "s3.upload_file(file_name, bucket_name, file_name)\n",
    "print(f\"Archivo {file_name} subido a S3 en el bucket {bucket_name}.\")\n",
    "\n",
    "##descargamos y procesamos datos desde S3\n",
    "#descargamos el archivo desde S3\n",
    "s3.download_file(bucket_name, file_name, f\"descargado_{file_name}\")\n",
    "\n",
    "#leemos y procesamos\n",
    "df = pd.read_csv(f\"descargado_{file_name}\")\n",
    "\n",
    "#limpieza: Llenar nulos, calcular ventas totales\n",
    "df.fillna({'cantidad': 1}, inplace=True)\n",
    "df['venta_total'] = df['precio'] * df['cantidad']\n",
    "\n",
    "#filtramos ventas mayores a $1000\n",
    "df_filtrado = df[df['venta_total'] > 1000]\n",
    "\n",
    "#guardamos datos procesados\n",
    "df_filtrado.to_csv('ventas_procesadas.csv', index=False)\n",
    "print(\"Datos procesados guardados en 'ventas_procesadas.csv'.\")\n",
    "#----------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##subiremos datos procesados a AWS RDS\n",
    "from sqlalchemy import create_engine\n",
    "#configuramos conexión a RDS\n",
    "engine = create_engine('postgresql://user:password@rds-endpoint.amazonaws.com/mydatabase')\n",
    "\n",
    "#cargamos datos a RDS\n",
    "df_filtrado.to_sql('ventas', engine, if_exists='replace', index=False)\n",
    "print(\"Datos subidos a RDS.\")\n",
    "#----------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##Consultas SQL avanzadas\n",
    "#filtramos ventas mayores a $1000 realizadas con tarjeta de crédito\n",
    "query_ventas = \"\"\"\n",
    "SELECT *\n",
    "FROM ventas\n",
    "WHERE metodo_pago = 'Crédito' AND venta_total > 1000;\n",
    "\"\"\"\n",
    "\n",
    "#encontrar la  sucursal con más ventas en un mes\n",
    "query_sucursal = \"\"\"\n",
    "SELECT sucursal, EXTRACT(MONTH FROM fecha) AS mes, SUM(venta_total) AS total_ventas\n",
    "FROM ventas\n",
    "GROUP BY sucursal, mes\n",
    "ORDER BY total_ventas DESC\n",
    "LIMIT 1;\n",
    "\"\"\"\n",
    "\n",
    "#creamos índice para optimizar consultas\n",
    "query_index = \"CREATE INDEX idx_fecha_sucursal ON ventas(fecha, sucursal);\"\n",
    "#----------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Preguntas de simulación\n",
    "#AWS: Subir múltiples archivos a S3\n",
    "import os\n",
    "\n",
    "for file in os.listdir('carpeta_local'):\n",
    "    s3.upload_file(f'carpeta_local/{file}', bucket_name, file)\n",
    "print(\"Archivos subidos exitosamente.\")\n",
    "\n",
    "#SQL: Detectar clientes frecuentes\n",
    "query_clientes_frecuentes = \"\"\"\n",
    "SELECT tipo_cliente, COUNT(*) AS cantidad_compras\n",
    "FROM ventas\n",
    "GROUP BY tipo_cliente\n",
    "HAVING COUNT(*) > 5;\n",
    "\"\"\"\n",
    "\n",
    "#Python: Detectar duplicados en un dataset\n",
    "duplicados = df[df.duplicated()]\n",
    "print(\"Duplicados encontrados:\\n\", duplicados)\n",
    "\n",
    "#Python: Uso de Pandas para anlálisis exploratorio de datos\n",
    "print(\"Estadísticas descriptivas:\\n\", df.describe())\n",
    "print(\"Valores nulos:\\n\", df.isnull().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
